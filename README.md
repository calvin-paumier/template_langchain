# ğŸ¤– Template LangChain Agent

Un template d'agent conversationnel intelligent basÃ© sur LangChain et LangGraph, capable de router automatiquement entre diffÃ©rents outils selon le type de question.

## ğŸ¯ FonctionnalitÃ©s

- **ğŸ”€ Routing intelligent** : Choix automatique entre RAG et TextToSQL selon le contexte
- **ğŸ—„ï¸ Text-to-SQL** : GÃ©nÃ©ration et exÃ©cution de requÃªtes SQL sur une base Sanrio
- **ğŸ“š RAG (Retrieval-Augmented Generation)** : Recherche vectorielle pour questions gÃ©nÃ©rales
- **ğŸ’­ MÃ©moire conversationnelle** : Gestion de l'historique par session
- **âš¡ OptimisÃ© UV** : Installation et gestion rapide des dÃ©pendances

## ğŸš€ Installation rapide

### PrÃ©requis
- Python 3.12.4+
- Docker & Docker Compose
- Git

### Setup complet en une commande
```bash
# 1. Clonage du projet
git clone <votre-repo>
cd template_langchain

# 2. Installation d'UV et environnement Python
make env

# 3. DÃ©marrage des services (PostgreSQL, Ollama)
make deploy

# 4. TÃ©lÃ©chargement des modÃ¨les IA
make install-models

# 5. Population de la base de donnÃ©es
make fill-db
```

## ğŸ”§ Configuration

### Fichier `.env`
CrÃ©ez un fichier `.env` Ã  la racine :

```bash
# Base de donnÃ©es PostgreSQL
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=my_db
POSTGRES_USER=my_user
POSTGRES_PASSWORD=my_password

# Ollama
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b
OLLAMA_EMBEDDING_MODEL=nomic-embed-text:latest
```

### Services Docker
Les services suivants sont automatiquement dÃ©marrÃ©s :
- **PostgreSQL** : Base de donnÃ©es principale
- **Ollama** : Serveur de modÃ¨les LLM locaux

## ğŸ’¬ Utilisation

Test possible en lanÃ§ant la commande :
```bash
make streamlit
```

## ğŸ› ï¸ Commandes Makefile

```bash
make help              # Affiche l'aide
make env               # Setup environnement UV
make deploy            # DÃ©marre docker-compose  
make install-models    # TÃ©lÃ©charge les modÃ¨les IA
make fill-db           # Remplit la base de donnÃ©es
make lint              # Lance Ruff
make streamlit         # Lance l'application Streamlit
```